{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dauphin95/data_spring/blob/master/DNN02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ1uE4CEUM36"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGDjqooPSwRD"
      },
      "source": [
        "df = pd.read_csv('credit_cards_dataset.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO35yiI5UNQl"
      },
      "source": [
        "X = df.drop( ['default.payment.next.month'], axis=1).values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u67wTfJUTb5"
      },
      "source": [
        "Y = df['default.payment.next.month'].values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hug2JnxCUV16"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0EEIm3cUaXK"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ept9nl9UoWJ"
      },
      "source": [
        "Standard Scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9FxjEC4UjVw"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lksgu9a8VLUb"
      },
      "source": [
        "sc = StandardScaler()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh_UQJOJVDrZ"
      },
      "source": [
        "X_train = sc.fit_transform(X_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "v7ZTgxjzVjMT",
        "outputId": "82cc0075-396a-42a3-ff1c-b6eed6311a3e"
      },
      "source": [
        "pd.DataFrame(X_train).describe().round(2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "      <td>21000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.73</td>\n",
              "      <td>-1.22</td>\n",
              "      <td>-1.24</td>\n",
              "      <td>-2.34</td>\n",
              "      <td>-2.97</td>\n",
              "      <td>-1.57</td>\n",
              "      <td>-1.76</td>\n",
              "      <td>-1.56</td>\n",
              "      <td>-1.53</td>\n",
              "      <td>-1.52</td>\n",
              "      <td>-1.53</td>\n",
              "      <td>-1.48</td>\n",
              "      <td>-2.95</td>\n",
              "      <td>-1.68</td>\n",
              "      <td>-1.56</td>\n",
              "      <td>-3.33</td>\n",
              "      <td>-2.01</td>\n",
              "      <td>-4.19</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-0.31</td>\n",
              "      <td>-0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.87</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>-1.24</td>\n",
              "      <td>-1.08</td>\n",
              "      <td>-1.05</td>\n",
              "      <td>-0.81</td>\n",
              "      <td>-0.87</td>\n",
              "      <td>-0.72</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.67</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>-0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.86</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>-0.37</td>\n",
              "      <td>-0.37</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.19</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.86</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.73</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0.81</td>\n",
              "      <td>5.24</td>\n",
              "      <td>2.78</td>\n",
              "      <td>4.28</td>\n",
              "      <td>7.11</td>\n",
              "      <td>6.77</td>\n",
              "      <td>6.84</td>\n",
              "      <td>7.03</td>\n",
              "      <td>7.29</td>\n",
              "      <td>7.17</td>\n",
              "      <td>12.47</td>\n",
              "      <td>13.19</td>\n",
              "      <td>23.35</td>\n",
              "      <td>13.28</td>\n",
              "      <td>14.66</td>\n",
              "      <td>15.60</td>\n",
              "      <td>51.47</td>\n",
              "      <td>66.83</td>\n",
              "      <td>48.89</td>\n",
              "      <td>38.23</td>\n",
              "      <td>26.62</td>\n",
              "      <td>29.46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2   ...        21        22        23\n",
              "count  21000.00  21000.00  21000.00  ...  21000.00  21000.00  21000.00\n",
              "mean      -0.00     -0.00     -0.00  ...      0.00      0.00     -0.00\n",
              "std        1.00      1.00      1.00  ...      1.00      1.00      1.00\n",
              "min       -1.73     -1.22     -1.24  ...     -0.30     -0.31     -0.30\n",
              "25%       -0.87     -0.91     -1.24  ...     -0.29     -0.29     -0.29\n",
              "50%        0.01     -0.21      0.81  ...     -0.21     -0.21     -0.21\n",
              "75%        0.86      0.56      0.81  ...     -0.06     -0.05     -0.07\n",
              "max        1.73      6.44      0.81  ...     38.23     26.62     29.46\n",
              "\n",
              "[8 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGi3mkVVV3K"
      },
      "source": [
        "X_test = sc.fit_transform(X_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmrPxfJnVcgx"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBJGPRpzS0ER"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create a network with 1 linear unit\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(units=30, input_shape=[24], activation='relu'),\n",
        "    layers.Dropout(rate=0.3),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(units=50,  activation='relu'),\n",
        "    layers.Dropout(rate=0.3),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(units=30,  activation='relu'),\n",
        "    layers.Dropout(rate=0.3),\n",
        "    layers.Dense(units=15),\n",
        "    layers.Dropout(rate=0.3),\n",
        "    layers.Dense(units=5),\n",
        "    layers.Dropout(rate=0.3),\n",
        "\n",
        "    layers.Dense(units=1, activation='sigmoid')\n",
        "\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9gnohGfTzry",
        "outputId": "d9c6ce01-487e-4a4b-fd5d-aa2a3a02a655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                750       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 30)                120       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                1550      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                1530      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 15)                465       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 80        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 4,701\n",
            "Trainable params: 4,541\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8BeMLQlX0Kz"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXNcpA33W1Hj"
      },
      "source": [
        "model.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()] )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYnVJd9bYOrr",
        "outputId": "53351d79-6464-4f4b-d7c2-94254b1a3d34"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=30, shuffle=True, verbose='auto')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "657/657 [==============================] - 6s 6ms/step - loss: 0.5785 - binary_accuracy: 0.7462\n",
            "Epoch 2/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.5039 - binary_accuracy: 0.7880\n",
            "Epoch 3/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4820 - binary_accuracy: 0.7980\n",
            "Epoch 4/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4759 - binary_accuracy: 0.7971\n",
            "Epoch 5/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4717 - binary_accuracy: 0.7991\n",
            "Epoch 6/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4682 - binary_accuracy: 0.7977\n",
            "Epoch 7/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4642 - binary_accuracy: 0.8011\n",
            "Epoch 8/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4639 - binary_accuracy: 0.8023\n",
            "Epoch 9/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4602 - binary_accuracy: 0.8021\n",
            "Epoch 10/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4580 - binary_accuracy: 0.8031\n",
            "Epoch 11/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4561 - binary_accuracy: 0.8048\n",
            "Epoch 12/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4570 - binary_accuracy: 0.8027\n",
            "Epoch 13/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4540 - binary_accuracy: 0.8034\n",
            "Epoch 14/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4573 - binary_accuracy: 0.8000\n",
            "Epoch 15/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4517 - binary_accuracy: 0.8055\n",
            "Epoch 16/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4542 - binary_accuracy: 0.8055\n",
            "Epoch 17/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4502 - binary_accuracy: 0.8060\n",
            "Epoch 18/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4513 - binary_accuracy: 0.8052\n",
            "Epoch 19/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4515 - binary_accuracy: 0.8045\n",
            "Epoch 20/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4519 - binary_accuracy: 0.8036\n",
            "Epoch 21/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4507 - binary_accuracy: 0.8042\n",
            "Epoch 22/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4497 - binary_accuracy: 0.8074\n",
            "Epoch 23/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4523 - binary_accuracy: 0.8055\n",
            "Epoch 24/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4483 - binary_accuracy: 0.8076\n",
            "Epoch 25/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4473 - binary_accuracy: 0.8054\n",
            "Epoch 26/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4478 - binary_accuracy: 0.8083\n",
            "Epoch 27/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4478 - binary_accuracy: 0.8093\n",
            "Epoch 28/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4481 - binary_accuracy: 0.8091\n",
            "Epoch 29/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4471 - binary_accuracy: 0.8079\n",
            "Epoch 30/30\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.4473 - binary_accuracy: 0.8075\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa870208550>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM5YpML4cD_2"
      },
      "source": [
        "y_predict = model.predict(X_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqV-f_ircdeF"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VFsNm4icW4E"
      },
      "source": [
        "y_predict = np.rint(y_predict)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kHXVaVzcj1h"
      },
      "source": [
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvvSuIb0cwRl",
        "outputId": "fd4feadd-fc93-483d-bce3-78b30ab61eb2"
      },
      "source": [
        "recall_score(Y_test, y_predict)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28622448979591836"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}